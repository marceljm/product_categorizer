{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING IN PRODUCT CATEGORIZATION:\n",
    "## APPLICATION OF A SUPERVISED LEARNING MODEL IN A REAL E-COMMERCE DATASET\n",
    "\n",
    "Using a machine learning approach, this project will show how to implement a\n",
    "simple and fast solution to the product categorization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 DATA EXPLORATION\n",
    "First let's take a look on our original data, a Walmart dataset with some millions of products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "programId                                                12011\n",
      "zupid                         6267bf6a0ebb5fb08b708bbc4954c45c\n",
      "name         Smart TV Sony KDL55W955B LED 55' 3D Full HD Sm...\n",
      "desc                                                       NaN\n",
      "price                                                     4999\n",
      "priceOld                                                   NaN\n",
      "brand                                                     Sony\n",
      "date                                       01/12/2017 11:03:00\n",
      "medium       https://static.wmobjects.com.br/imgres/arquivo...\n",
      "large                                                      NaN\n",
      "link         http://ad.zanox.com/ppc/?38441474C295166823&UL...\n",
      "path                              Eletrônicos / TVs / Smart TV\n",
      "main                                                       NaN\n",
      "sub                                                        NaN\n",
      "third                                                      NaN\n",
      "ean                                                4.90552e+12\n",
      "small                                                      NaN\n",
      "available                                Disponibilidade:false\n",
      "img1                                                       NaN\n",
      "gender                                                     NaN\n",
      "Name: 1919944, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1.2 GB\n",
    "INPUT_FILE = 'dataset/zxpd_201712121136_12011_38441474.csv'\n",
    "\n",
    "# read input file\n",
    "data = pd.read_csv(INPUT_FILE, sep=';', encoding='utf-8',names = ['programId',\n",
    "                                                                   'zupid',\n",
    "                                                                   'name',\n",
    "                                                                   'desc',\n",
    "                                                                   'price',\n",
    "                                                                   'priceOld',\n",
    "                                                                   'brand',\n",
    "                                                                   'date',\n",
    "                                                                   'medium',\n",
    "                                                                   'large',\n",
    "                                                                   'link',\n",
    "                                                                   'path',\n",
    "                                                                   'main',\n",
    "                                                                   'sub',\n",
    "                                                                   'third',\n",
    "                                                                   'ean',\n",
    "                                                                   'small',\n",
    "                                                                   'available',\n",
    "                                                                   'img1',\n",
    "                                                                   'gender'])\n",
    "\n",
    "# print a product\n",
    "print(data.loc[1919944])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2 GB\n",
      "2,625,975 products\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# get metadata\n",
    "statinfo = os.stat(INPUT_FILE)\n",
    "\n",
    "# print file size, in GB\n",
    "print(format(statinfo.st_size / pow(1024,3),'.2') + ' GB')\n",
    "\n",
    "# print number or products (rows)\n",
    "print(format(len(data),',') + ' products')\n",
    "\n",
    "# free memory\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 DATA PREPROCESSING\n",
    "Now let's tranform the original data. We will normalize that, create new columns and remove all the useless information to our model, including ~1.4 millions of unavailable products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223.81 seconds\n"
     ]
    }
   ],
   "source": [
    "from dsLib import *\n",
    "from time import time\n",
    "\n",
    "OUTPUT_FILE = 'dataset/preprocessed.csv'\n",
    "\n",
    "# start time\n",
    "start = time()\n",
    "\n",
    "# open output file\n",
    "output = open(OUTPUT_FILE, 'w')\n",
    "\n",
    "# read input file\n",
    "with open(INPUT_FILE, 'r') as file:\n",
    "    \n",
    "    # write header\n",
    "    output.write(header())\n",
    "    \n",
    "    # for each line...\n",
    "    for line in file:\n",
    "        \n",
    "        # transform in list\n",
    "        lst = transform_line(line)\n",
    "        \n",
    "        # valid\n",
    "        if (not valid(lst)):\n",
    "            continue\n",
    "            \n",
    "        # apply changes\n",
    "        line = format_line(lst)\n",
    "        \n",
    "        # save\n",
    "        output.write(line)\n",
    "\n",
    "# close file\n",
    "output.close()\n",
    "\n",
    "# print preprocessing time\n",
    "print('{:.2f} seconds'.format(time() - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                                     perfume 212 sexy\n",
      "brand                                    carolina herrera\n",
      "gender                                                  1\n",
      "room                                                     \n",
      "vehicle                                                  \n",
      "console                                                  \n",
      "device                                                   \n",
      "pet                                                      \n",
      "mattress                                                 \n",
      "cup                                                      \n",
      "category    Perfumaria e Cosméticos / Perfumes / Feminino\n",
      "Name: 1211643, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# read output file\n",
    "data = pd.read_csv(OUTPUT_FILE, sep=';', encoding='utf-8',names = ['name',\n",
    "                                                                   'brand',\n",
    "                                                                   'gender',\n",
    "                                                                   'room',\n",
    "                                                                   'vehicle',\n",
    "                                                                   'console',\n",
    "                                                                   'device',\n",
    "                                                                   'pet',\n",
    "                                                                   'mattress',\n",
    "                                                                   'cup',\n",
    "                                                                   'category'])\n",
    "\n",
    "# print a product\n",
    "print(data.loc[1211643])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12 GB\n",
      "1,235,888 products\n"
     ]
    }
   ],
   "source": [
    "# get metadata\n",
    "statinfo = os.stat(OUTPUT_FILE)\n",
    "\n",
    "# print file size, in GB\n",
    "print(format(statinfo.st_size / pow(1024,3),'.2') + ' GB')\n",
    "\n",
    "# print number or products (rows)\n",
    "print(format(len(data),',') + ' products')\n",
    "\n",
    "# free memory\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 IMPLEMENTATION\n",
    "With our dataset ready, let's read, encode and train the data. And, to finish, let's predict the product categories with our Decision Tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 90.13%\n",
      "141.62 seconds\n"
     ]
    }
   ],
   "source": [
    "from mlLib import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "INPUT_FILE = OUTPUT_FILE\n",
    "\n",
    "NUMBER_OF_FEATURES = 10\n",
    "\n",
    "# start time\n",
    "start = time()\n",
    "\n",
    "# read data\n",
    "data = pd.read_csv(INPUT_FILE, sep=';', header=0, converters={'price': float}, encoding='utf-8')\n",
    "\n",
    "# price scaling\n",
    "# data['price'] = np.log(data['price'])\n",
    "\n",
    "# feature data (all rows, all columns except the last)\n",
    "X_all = data.iloc[:, :data.shape[1] - 1]\n",
    "\n",
    "# target data (all rows, only the last column)\n",
    "y_all = data.iloc[:, data.shape[1] - 1]\n",
    "\n",
    "# save memory\n",
    "del data\n",
    "\n",
    "# encode features\n",
    "X_encoder = []\n",
    "for col in range(0, NUMBER_OF_FEATURES):\n",
    "    X_encoder.append(preprocessing.LabelEncoder())\n",
    "    X_encoder[col].fit(X_all.iloc[:, col].astype('str'))\n",
    "    X_all.iloc[:, col] = X_encoder[col].transform(X_all.iloc[:, col].astype('str'))\n",
    "\n",
    "# encode labels\n",
    "y_encoder = preprocessing.LabelEncoder()\n",
    "y_encoder.fit(y_all)\n",
    "y_all = y_encoder.transform(y_all)\n",
    "\n",
    "# shuffle and split the dataset into training and testing points\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=55)\n",
    "\n",
    "# initialize the classifier\n",
    "clf = DecisionTreeClassifier(random_state=86)\n",
    "\n",
    "# grid Search\n",
    "# clf = best_estimator(clf, X_train, y_train)\n",
    "\n",
    "# fit\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict (save memory!)\n",
    "# predict_loop(clf, X_test, y_test, X_encoder, y_encoder)\n",
    "\n",
    "# predict (no output)\n",
    "print('accuracy: {:.2f}%'.format(100. * accuracy_score(y_test, clf.predict(X_test))))\n",
    "\n",
    "# print processing time\n",
    "print('{:.2f} seconds'.format(time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 RESULTS\n",
    "So our model was able to train e predict ~1.2 million of products in ~2.5 minutes with ~90% of accuracy. Not bad.\n",
    "\n",
    "PS: it's possible to visualize the wrong predictions, uncommenting the *predict_loop()* method. However, as the data will need to be decoded, the whole process will take ~10 minutes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
